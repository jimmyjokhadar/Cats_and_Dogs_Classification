{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing of Microsoft Cats vs. Dogs Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the libraries.\n",
    "Make sure to set the Kaggle API in order to get the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import kagglehub as kh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the dataset from Kaggle.\n",
    "The function will return the path of the data after downloading it. \\\n",
    "Usually datasets will be saved in ~/.cache/kagglehub/datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/jimmy/.cache/kagglehub/datasets/shaunthesheep/microsoft-catsvsdogs-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "path = kh.dataset_download(\"shaunthesheep/microsoft-catsvsdogs-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a function that loads and process the data, by adding padding to make images squares, resizing the images and converting them to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(path: str, size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Processes images in a specified folder, resizes them to a given size, \n",
    "    and returns the processed images as a `NumPy` array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Path to the folder containing the input images.\n",
    "    size : int\n",
    "        Target size (in pixels) to which the images should be resized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Processed images as a `NumPy` array.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function assumes that all images in the `path` directory are of \n",
    "      a compatible format (e.g., JPG, PNG).\n",
    "    - The images are resized to (size, size) pixels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for image in os.listdir(path):\n",
    "        if not image.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(f'{path}/{image}')\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        # Add padding to the image\n",
    "        h, w, _ = img.shape\n",
    "        if h > w:\n",
    "            pad = (h - w) // 2\n",
    "            img = cv2.copyMakeBorder(img, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "        else:\n",
    "            pad = (w - h) // 2\n",
    "            img = cv2.copyMakeBorder(img, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "        \n",
    "        # Convert the image to greyscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (size, size))\n",
    "\n",
    "        # Flatten the image\n",
    "        img = img.flatten()\n",
    "\n",
    "        # Append the image to the list\n",
    "        images.append(img.astype(np.uint8))\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 239 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 399 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    }
   ],
   "source": [
    "cat_images = process_images(f'{path}/PetImages/Cat', size=128)\n",
    "dog_images = process_images(f'{path}/PetImages/Dog', size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the dataset into training_cats, training_dogs, testing_cats, and testing_dogs equally, then concatenating training images and testing images respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "indices_cats = np.random.permutation(cat_images.shape[0])\n",
    "indices_dogs = np.random.permutation(dog_images.shape[0])\n",
    "\n",
    "train_cats = cat_images[indices_cats[:int(0.8 * cat_images.shape[0])]]\n",
    "train_dogs = dog_images[indices_dogs[:int(0.8 * dog_images.shape[0])]]\n",
    "test_cats = cat_images[indices_cats[int(0.8 * cat_images.shape[0]):]]\n",
    "test_dogs = dog_images[indices_dogs[int(0.8 * dog_images.shape[0]):]]\n",
    "\n",
    "training_images = np.concatenate((train_cats, train_dogs))\n",
    "training_labels = np.concatenate((np.zeros(train_cats.shape[0]), np.ones(train_dogs.shape[0])))\n",
    "\n",
    "testing_images = np.concatenate((test_cats, test_dogs))\n",
    "testing_labels = np.concatenate((np.zeros(test_cats.shape[0]), np.ones(test_dogs.shape[0])))\n",
    "\n",
    "shuffle_train = np.random.permutation(training_images.shape[0])\n",
    "shuffle_test = np.random.permutation(testing_images.shape[0])\n",
    "\n",
    "train_images = training_images[shuffle_train]\n",
    "train_labels = training_labels[shuffle_train]\n",
    "test_images = testing_images[shuffle_test]\n",
    "test_labels = testing_labels[shuffle_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the cleaned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('dataset'):\n",
    "    os.makedirs('dataset')\n",
    "np.savez_compressed('dataset/train.npz', images=train_images, labels=train_labels)\n",
    "np.savez_compressed('dataset/test.npz', images=test_images, labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that images were not normalized, to be able to reduce the size of saved files by using uint8 type."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
